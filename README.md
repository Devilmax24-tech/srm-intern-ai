# ğŸ–¼ï¸ CIFAR-10 Image Classification
## Deep Learning Project - SRM Intern

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.8+-FF6F00?logo=tensorflow)](https://www.tensorflow.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Accuracy](https://img.shields.io/badge/Accuracy-86.71%25-brightgreen)]()

---

## ğŸ“‹ Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Train/Validation Split](#trainvalidation-split)
- [Model Architectures](#model-architectures)
- [Results](#results)
- [Metrics Reported](#metrics-reported)
- [Installation](#installation)
- [Usage](#usage)
- [Repository Structure](#repository-structure)
- [License](#license)

---

## ğŸ¯ Project Overview

This project implements two CNN architectures for CIFAR-10 image classification:
- **Baseline CNN**: Simple 3-layer convolutional network
- **Improved CNN**: Deep network with augmentation + regularization

**Best Result:** `86.71%` Test Accuracy (Improved CNN)

---

## ğŸ“Š Dataset

| Description | Value |
|------------|-------|
| **Classes** | 10 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) |
| **Image Size** | 32x32x3 (RGB) |
| **Total Images** | 60,000 |
| **Training Set** | 50,000 |
| **Test Set** | 10,000 |

---

## âœ‚ï¸ Train/Validation Split

python
from sklearn.model_selection import train_test_split

# Load CIFAR-10
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# Split training data: 80% train, 20% validation
x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train,
    test_size=0.2,        # 20% for validation
    random_state=42,      # Reproducible results
    stratify=y_train      # Equal class distribution
)

<img width="729" height="322" alt="Screenshot From 2026-02-11 22-01-02" src="https://github.com/user-attachments/assets/d130b379-0c5c-41dd-b084-951bb3ba2f45" />

ğŸ›ï¸ Model Architectures

1ï¸âƒ£ Baseline CNN

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input 32x32x3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D 32 (3x3)â”‚
â”‚    ReLU + Same  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MaxPool (2x2) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D 64 (3x3)â”‚
â”‚    ReLU + Same  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MaxPool (2x2) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D 64 (3x3)â”‚
â”‚    ReLU + Same  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Flatten     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Dense 64     â”‚
â”‚     ReLU        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Dense 10     â”‚
â”‚   Softmax       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Parameters: 319,178

2ï¸âƒ£ Improved CNN
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Input 32x32x3     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA AUGMENTATION  â”‚
â”‚  Flip, Rotate, Zoom  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Conv2D 32 + BN     â”‚
â”‚   Conv2D 32 + BN     â”‚
â”‚   MaxPool + Drop(0.2)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Conv2D 64 + BN     â”‚
â”‚   Conv2D 64 + BN     â”‚
â”‚   MaxPool + Drop(0.3)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conv2D 128 + BN     â”‚
â”‚  Conv2D 128 + BN     â”‚
â”‚  MaxPool + Drop(0.4) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Flatten         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Dense 256 + BN    â”‚
â”‚     Dropout (0.5)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Dense 10         â”‚
â”‚      Softmax         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Parameters: 816,938

ğŸ† Results

ğŸ¥‡ Best Model: Improved CNN
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           â˜… BEST RESULT ACHIEVED â˜…             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Test Accuracy:         86.71%                 â•‘
â•‘  Test Loss:             0.4532                 â•‘
â•‘  Validation Accuracy:   87.40%                 â•‘
â•‘  Parameters:            816,938                â•‘
â•‘  Inference Time:        1.2ms/image           â•‘
â•‘  Improvement vs Base:   +14.37%               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<img width="541" height="408" alt="Screenshot From 2026-02-11 22-14-57" src="https://github.com/user-attachments/assets/0810f54c-9754-474c-867e-80b085555f7e" />


<img width="514" height="482" alt="Screenshot From 2026-02-11 22-16-16" src="https://github.com/user-attachments/assets/88323bf1-6e8b-42b8-bd57-557a08178738" />


ğŸ“‰ Confusion Matrix Summary
          Predicted
        A  Au B  C  D  Do F  H  S  T  â† Actual
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     A  â”‚88 1  2  0  0  0  0  0  6  1â”‚
     Au â”‚1 93  0  0  0  0  0  0  2  2â”‚
     B  â”‚2  0 81  4  4  3  2  2  1  1â”‚
     C  â”‚1  0  3 79  3  7  2  2  1  1â”‚
     D  â”‚0  0  4  3 83  3  4  2  0  0â”‚
     Do â”‚0  0  4  7  3 80  2  3  0  1â”‚
     F  â”‚1  0  3  3  2  2 90  1  0  0â”‚
     H  â”‚0  0  2  2  3  3  2 87  0  1â”‚
     S  â”‚5  1  1  0  0  0  0  0 91  1â”‚
     T  â”‚2  2  0  0  0  0  0  0  1 92â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ“ Metrics Reported

<img width="676" height="336" alt="Screenshot From 2026-02-11 22-17-41" src="https://github.com/user-attachments/assets/9db35755-1e8b-4959-9e3c-b0d440521e6c" />

<img width="548" height="362" alt="Screenshot From 2026-02-11 22-18-28" src="https://github.com/user-attachments/assets/2f331c06-49bd-4108-a03b-dc029e1adf28" />

ğŸ’» Installation

Requirements:
Python 3.8+
TensorFlow 2.8+
4GB+ RAM

Quick Setup
# Clone repository
git clone https://github.com/yourusername/cifar10-classification.git
cd cifar10-classification

# Install dependencies
pip install -r requirements.txt

requirements.txt
tensorflow>=2.8.0
numpy>=1.21.0
matplotlib>=3.5.0
seaborn>=0.11.0
pandas>=1.3.0
scikit-learn>=1.0.0
jupyter>=1.0.0

ğŸš€ Usage

1ï¸âƒ£ Training Baseline Model
python train_baseline.py

2ï¸âƒ£ Training Improved Model
python train_improved.py

3ï¸âƒ£ Evaluate Models
python evaluate.py

4ï¸âƒ£ Quick Prediction

from tensorflow import keras
import numpy as np

# Load model
model = keras.models.load_model('models/improved_cifar10_model.h5')

# Predict
predictions = model.predict(image)
class_idx = np.argmax(predictions)
confidence = np.max(predictions)

print(f"Predicted: {class_names[class_idx]} ({confidence:.2%})")


ğŸ”‘ Key Improvements Summary
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMPROVEMENTS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ” Data Augmentation      â†’ +5-8% accuracy              â”‚
â”‚  âœ” Batch Normalization    â†’ 2x faster convergence       â”‚
â”‚  âœ” Dropout               â†’ No overfitting              â”‚
â”‚  âœ” Deeper Architecture    â†’ Better feature extraction   â”‚
â”‚  âœ” Learning Rate Scheduling â†’ Optimal convergence      â”‚
â”‚  âœ” Early Stopping        â†’ Best weights saved         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ License
This project is licensed under the MIT License - see the LICENSE file for details.
